{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b36ac7b-2d5c-4569-af14-ab28ce816b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f2fec7-3edc-435b-b765-5023cd49b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9d571c-26fb-4cdd-985d-be243b56323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af9b616-28f1-454f-8e60-5aca3d86fe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_dataset[0]['image']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4fe0f21-f5ac-49f1-87e1-1392d7f50ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing LeNet\n",
    "# Initial Layer of convolution with feature map/ filter count of 6\n",
    "# Kernel size 5, output size will be (28 - 5) + 1 = 24\n",
    "# Let's build convolution Layer, so that I could generalize any architecture implementation\n",
    "class Conv_Layer:\n",
    "    def __init__(self, input_channel, input_size, stride, filter_shape, output_chanel_or_filter_num, batch_size,padding=0):\n",
    "        self.input_channel = input_channel # channel means to multiply with same filter in same place and adding the input_channel times\n",
    "        self.input_size = input_size # size of input or for first conv layer, it will be image resolution\n",
    "        self.stride = stride\n",
    "        self.filter_shape = filter_shape\n",
    "        self.output_chanel = output_chanel_or_filter_num # This could also be called the number of filer numbers\n",
    "        self.batch_size = batch_size\n",
    "        self.padding = padding\n",
    "        self.initialize_filer_weights()\n",
    "        self.initialize_filter_biases()\n",
    "\n",
    "        # In a normalize standarizarion here,\n",
    "        # the shape of input is (input_channel, input_shape, input_shape)\n",
    "    \n",
    "    def initialize_filer_weights(self):\n",
    "        # This structure defines every filter weights for each input channel, and it goes for each output channel\n",
    "        self.filter_weights = 0.01 * np.random.randn(self.output_chanel, self.input_channel,self.filter_shape,self.filter_shape)\n",
    "\n",
    "    def initialize_filter_biases(self):\n",
    "        self.filter_biases = np.zeros((self.output_chanel, 1))\n",
    "        # print(f'biases:: {self.filter_biases}')\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.inputs = input\n",
    "        # self.output = []\n",
    "        single_filter_output_shape = int(((self.input_size - self.filter_shape)/self.stride) + 1) if self.padding == 0 else \\\n",
    "        int(((self.input_size - self.filter_shape + 2 * self.padding)/self.stride) + 1)\n",
    "\n",
    "        # We are assuming that the input image shape, the height and width is always symmetrical or equal\n",
    "        self.output = np.zeros((self.batch_size,self.output_chanel,single_filter_output_shape,single_filter_output_shape))\n",
    "        for i, filter in enumerate(self.filter_weights):\n",
    "            # Now I will iterate through column and through row\n",
    "            for row in range (0,self.input_size,self.stride):\n",
    "                \n",
    "                # This projects from overflowing through columns (Verically)\n",
    "                if(row > self.input_size - self.filter_shape):\n",
    "                    break\n",
    "                    \n",
    "                for column in range (0,self.input_size,self.stride):\n",
    "\n",
    "                    # This projects from overflowing through columns (Horizontally)\n",
    "                    if(column > self.input_size - self.filter_shape):\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        # Do multiplication, do slice among input channels, multiply, sum and append to output_per_filter\n",
    "                        multi_channel_filter_feature_block =  self.inputs[:,:,row:self.filter_shape + row, column:self.filter_shape + column]\n",
    "                        # Now multiplying each of the arrays with filter, and adding each and each one of them next\n",
    "                        filter_applied_frame = multi_channel_filter_feature_block * filter\n",
    "                        # added all filter per output channel fashion\n",
    "                        # print(f'i is:: {i} and {self.filter_biases[0]}, column is {column}')\n",
    "                        \n",
    "                        # This needs to updated to only be summed up in internal axis along each batch and there internal multiplicative product\n",
    "                        self.output[:,i, row, column] =  filter_applied_frame.sum(axis=(1,2,3)) + self.filter_biases[i]\n",
    "\n",
    "    # Need to calculate gradients for both filters and dinputs\n",
    "    # first calculating for dinputs\n",
    "    def backward(self,dvalues):\n",
    "        self.dbiases = np.sum(dvalues, axis=(0, 2, 3))\n",
    "        self.dinputs = np.zeros_like(self.inputs , dtype=np.float64)\n",
    "        # this is dweights or dfilter_weights\n",
    "        self.dweights = np.zeros_like(self.filter_weights)\n",
    "        for i, filter in enumerate(self.filter_weights):\n",
    "\n",
    "            # Now I will iterate through column and through row\n",
    "            for row in range (0,self.output[0].shape[1],self.stride):\n",
    "\n",
    "                # This projects from overflowing through columns (Verically)\n",
    "                if(row > self.input_size - self.filter_shape):\n",
    "                    break\n",
    "\n",
    "                # As the output shape is output_channel, row, column\n",
    "                for column in range (0,self.output[0].shape[1],self.stride):\n",
    "\n",
    "                    # This projects from overflowing through columns (Horizontally)\n",
    "                    if(column > self.input_size - self.filter_shape):\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        # Do multiplication, do slice among input channels, multiply, sum and append to output_per_filter\n",
    "                        # dvalue = dvalues[:,i,row,column]\n",
    "                        dinputs_gradual_values = dvalues[:, i, row, column][:, None, None, None] * filter[None, :, :, :]\n",
    "                       # Already has correct shape: (batch_size, input_channel, fh, fw)\n",
    "                        self.dinputs[:, :, row:row + self.filter_shape, column: column + self.filter_shape] += dinputs_gradual_values\n",
    "\n",
    "                        dweights_gradual_values = (dvalues[:, i, row, column])[:, None, None, None] \\\n",
    "                        * (self.inputs[:, :, row: row + self.filter_shape, column: column + self.filter_shape])\n",
    "                        dweights_gradual_values = dweights_gradual_values.sum(axis=0)\n",
    "                        # print(f'dweights_gradual_values shape:: {dweights_gradual_values.shape}')\n",
    "                        self.dweights[i, :, :,:] += dweights_gradual_values\n",
    "\n",
    "                     \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80706de-f015-4491-975f-799d78ac2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no learning parameters in Pooling\n",
    "class Pooling:\n",
    "    def __init__(self,pooling_frame_size, input_channel, input_size,batch_size,stride=0):\n",
    "        self.pooling_frame_size = pooling_frame_size\n",
    "        self.input_channel = input_channel\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if(stride != 0):\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = self.pooling_frame_size\n",
    "        \n",
    "    def pooling(self,inputs):\n",
    "        pass\n",
    "\n",
    "    def backward(self,dvalues):\n",
    "        pass\n",
    "\n",
    "class Average_Pooling(Pooling):\n",
    "    def __init__(self,pooling_frame_size, input_channel, input_size,batch_size,stride=0):\n",
    "        super().__init__(pooling_frame_size, input_channel, input_size,batch_size,stride)\n",
    "        \n",
    "\n",
    "    def pooling(self,inputs):\n",
    "        self.inputs = inputs\n",
    "        # self.output = []\n",
    "        self.output = np.zeros((self.batch_size, self.input_channel, int(((self.input_size - self.pooling_frame_size)/self.stride) + 1), \\\n",
    "                               int((self.input_size - self.pooling_frame_size)/self.stride) + 1))\n",
    "        \n",
    "        for i in range(self.input_channel):\n",
    "            # Now I will iterate through column and through row\n",
    "            for row in range (0,self.input_size,self.stride):\n",
    "\n",
    "                # This projects from overflowing through columns (Verically)\n",
    "                if(row > self.input_size - self.pooling_frame_size):\n",
    "                    break\n",
    "                    \n",
    "                for column in range (0,self.input_size,self.stride):\n",
    "\n",
    "                    # This projects from overflowing through columns (Horizontally)\n",
    "                    if(column > self.input_size - self.pooling_frame_size):\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        # Do multiplication, do slice among input channels, multiply, sum and append to output_per_filter\n",
    "                        # now we are also taking batch_size into consideration, so, few things need to change\n",
    "                        # input_shape = batch_size, input_channel, input_size, input_size \n",
    "                        average_pooling_section = self.inputs[:,i, row:self.pooling_frame_size + row, column:self.pooling_frame_size+ column]\n",
    "                        # I used axis=(1,2) not axis=(1,2,3) because, since i is single dimension, it just omits it, so shape becomes\n",
    "                        # batch_size, pooling_frame, pooling_frame\n",
    "                        average = np.mean(average_pooling_section, axis=(1,2)) # need to average up only on per batch basis\n",
    "                        # because we are outputting in a smaller size than input, also the indexing is supposed to go from 0 to more that's why //\n",
    "                        self.output[:, i, row // self.stride, column // self.stride] = average\n",
    "    \n",
    "\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = np.ones_like(self.inputs) # It isn't proper dinputs, but more of a initial filter that hepls to caluclate the dinputs\n",
    "        for i in range(self.input_channel):\n",
    "            # the shape of dvalues will be, batch_size, input_filter channel, input_size reduced by pooling frame, input_size reduced by pooling frame\n",
    "            # for input_filter in range(self.input_size):\n",
    "                # we are considering row and column being symmetrical\n",
    "                for row in range(self.output.shape[2]):\n",
    "                    for column in range(dvalues.shape[2]):\n",
    "                        # Now mutiply the block with specific elements\n",
    "                        # modifying the ones_like variable cause it's average, and every elements are involved\n",
    "                        row_specific = 0 if row == 0 else row * self.pooling_frame_size\n",
    "                        column_specific = 0 if column == 0 else column * self.pooling_frame_size\n",
    "\n",
    "                        gradual_dinputs = (1/(self.pooling_frame_size ** 2))* dvalues[:,i,row,column]\n",
    "\n",
    "                        gradual_dinputs = gradual_dinputs[:, np.newaxis,np.newaxis]\n",
    "                        gradual_dinputs = np.broadcast_to(gradual_dinputs, (self.batch_size, self.pooling_frame_size,self.pooling_frame_size))\n",
    "                        \n",
    "                        self.dinputs[:,i,row_specific: row_specific + self.pooling_frame_size, column_specific: column_specific \\\n",
    "                        + self.pooling_frame_size] += gradual_dinputs\n",
    "                        \n",
    "       \n",
    "        # # This would also be wrong, as I have to expand dvalues dimentsion to dinputs size, dvalues shape is row/2 * column/2\n",
    "        # self.dinputs = (1/(self.pooling_frame_size * 2)) * dvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa26e0c2-500a-44e8-8fa8-e0c7266a15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pooling(Pooling):\n",
    "    def __init__(self,pooling_frame_size, input_channel, input_size, stride=0):\n",
    "        super().__init__(pooling_frame_size, input_channel, input_size,stride)\n",
    "\n",
    "    def pooling(self,inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = []\n",
    "        # Entering 1 where ever the max value is choosen from\n",
    "        # By the way the filter name doesnot mean filter like for CNN, it's just used as normal english word\n",
    "        self.dinputs_max_filter = np.zeros_like(self.inputs)\n",
    "        \n",
    "        for i in range(self.input_channel):\n",
    "            output_per_filter = []\n",
    "            # Now I will iterate through column and through row\n",
    "            for j in range (self.input_size):\n",
    "\n",
    "                output_per_filter_row = []\n",
    "                # This projects from overflowing through columns (Verically)\n",
    "                if(j > self.input_size - self.pooling_frame_size):\n",
    "                    break\n",
    "                    \n",
    "                for k in range (self.input_size):\n",
    "\n",
    "                    # This projects from overflowing through columns (Horizontally)\n",
    "                    if(k > self.input_size - self.pooling_frame_size):\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        # Do multiplication, do slice among input channels, multiply, sum and append to output_per_filter\n",
    "                        average_pooling_section = self.inputs[i, j:self.pooling_frame_size + j, k:self.pooling_frame_size+ k]\n",
    "                        max_val = np.max(average_pooling_section)\n",
    "                        output_per_filter_row.append(max_val)\n",
    "\n",
    "                        row= -1\n",
    "                        column = -1\n",
    "                        flat_index_argmax = np.argmax(average_pooling_section)\n",
    "                        row = int(flat_index_argmax / self.pooling_frame_size)\n",
    "                        column = flat_index_argmax % self.pooling_frame_size\n",
    "\n",
    "                        # Might need to test if this really works or not\n",
    "                        self.dinputs[i,j+row, k+column] = 1\n",
    "\n",
    "                    k+=self.stride\n",
    "                output_per_filter.append(output_per_filter_row)\n",
    "                j+=self.stride\n",
    "            \n",
    "            self.output.append(output_per_filter)\n",
    "        self.output = np.array(self.output)\n",
    "\n",
    "    # I haven't fixed this max_pooling backward, will do that very soon, just feeling lazy, could just look to average pooling, where impl is correct\n",
    "    def backward(self,dvalues):\n",
    "        for i in range(self.input_channel):\n",
    "            for dvalue in dvalues:\n",
    "                for row in range(dvalue.shape[0]):\n",
    "                    for column in range(dvalue.shape[1]):\n",
    "                        # Now mutiply the block with specific elements\n",
    "                        # modifying the ones_like variable cause it's average, and every elements are involved\n",
    "                        row_specific = 0 if row == 0 else row * self.pooling_frame_size\n",
    "                        self.dinputs_max_filter[i,row: row + self.pooling_frame_size, column: column + self.pooling_frame_size] = \\\n",
    "                        self.dinputs_max_filter * dvalues\n",
    "\n",
    "        \n",
    "        # # This is wrong, the shape is not right here dvalues has shape that is (row/2, column/2) in reference to self.dinputs\n",
    "        # self.dinputs = self.dinputs_max_filter * dvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561ec472-feec-4a06-813a-8086c4c38ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initializing weights and biases\n",
    "\n",
    "        # We are initializing the values of weight in form of (n_inputs, n_neurons) just to save us time from transposing while\n",
    "        # multiplying with batches of input as batch size would be (batch_size, n_inputs), so input @ weights\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n",
    "\n",
    "        # Initially initializing at 0\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        # keeping in inputs, to calculate gradient for weights\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self,dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ac282e-e9e2-4af2-a320-c388fac1c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Relu:\n",
    "\n",
    "    def feed_forward(self,inputs):\n",
    "\n",
    "        #Also keeping in the inputs to make the backward pass\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        # Relu basically means take input value if it is bigger than 0, else just make it 0\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "139952fa-5886-4c4a-8d5a-db7f0afed7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "\n",
    "    def feed_forward(self,inputs):\n",
    "        normalized_val_exp = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        \n",
    "        probabilities_value = normalized_val_exp / np.sum(normalized_val_exp, axis=1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities_value\n",
    "\n",
    "    def backward(self,dvalues):\n",
    "\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        for index, (single_softmax_output ,single_sample_CCELoss_dval) in \\\n",
    "        enumerate(zip(self.output, dvalues)):\n",
    "\n",
    "            # reshape softmax output of final layer say [1, 2, 3] is now [[1],[2],[3]]\n",
    "            single_softmax_output = single_softmax_output.reshape(-1,1)\n",
    "    \n",
    "            jacobian_matrix = np.diagflat(single_softmax_output) - \\\n",
    "                                np.dot(single_softmax_output, single_softmax_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_sample_CCELoss_dval)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d6c588-8867-4664-b04b-29cad6d3ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "\n",
    "    # We are averaging all the errors in a batch\n",
    "    #output_val is predicted_value\n",
    "    def calculate(self,output_val,true_class):\n",
    "\n",
    "        loss_along_each_itter_inBatch = self.feed_forward(output_val,true_class)\n",
    "\n",
    "        averaged_err = np.mean(loss_along_each_itter_inBatch)\n",
    "\n",
    "        return averaged_err\n",
    "        \n",
    "\n",
    "class Loss_CrossCategorical(Loss):\n",
    "\n",
    "    def feed_forward(self,output_val,true_class):\n",
    "\n",
    "        number_of_samples = len(output_val)\n",
    "    \n",
    "    \n",
    "        # Clipping true_class prediction as it isn't 0 or 1\n",
    "    \n",
    "        # 1e-7 is lower limit and 1 - 1e-7 is upper limit\n",
    "        \n",
    "        clipped_val = np.clip(output_val, 1e-7, 1- 1e-7)\n",
    "        \n",
    "        # considering the output or true_class in in format [0,1,0,0,2,1,0]\n",
    "        # here the output class per each sample is corresponding index\n",
    "    \n",
    "        #considering true_class is in this format\n",
    "    \n",
    "        correct_confidences = clipped_val[range(number_of_samples), true_class]\n",
    "    \n",
    "        # Now calculating Loss\n",
    "    \n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "    \n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # here dvalues means softmax output or say prediction in final layer\n",
    "    def backward(self, dvalues, true_class):\n",
    "\n",
    "        number_of_possible_classes = len(dvalues[0])\n",
    "\n",
    "        number_of_samples = len(dvalues)\n",
    "\n",
    "        # So that division by 0 or value near 0 doesn't divide anything\n",
    "        clipped_val = np.clip(dvalues, 1e-7, 1- 1e-7)\n",
    "\n",
    "        # One hot encoding true class through index assigning\n",
    "        true_class_eye_format = np.eye(number_of_possible_classes)[true_class]\n",
    "        \n",
    "        # The shape of true_class_eye_format will be (batch_size, number_of_possible_class) or (batch_size, final_layer_number_of_neurons)\n",
    "        # same as that of softmax\n",
    "        \n",
    "        self.dinputs = - true_class_eye_format / clipped_val\n",
    "\n",
    "        # Normalizing gradient\n",
    "        self.dinputs = self.dinputs / number_of_samples\n",
    "\n",
    "\n",
    "# Combined version of cross-categorical entropy loss and softmax partial derivate version is left on purpose\n",
    "# I will do that after some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baeea7af-d62e-42d1-a776-1d3d3f53d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "    def calculate(self,predictiction_prop, true_class):\n",
    "        # Calcualting argmax per row\n",
    "        predicted_class = np.argmax(predictiction_prop, axis=1)\n",
    "\n",
    "        accuracy = np.mean(predicted_class == true_class)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eccc1f5-36a6-4bc2-a649-a537c72ef017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "    def __init__(self,lr = 1.0):\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def update_params(self,layer):\n",
    "        layer.weights -= self.learning_rate * layer.dweights\n",
    "        layer.biases -= self.learning_rate * layer.dbiases\n",
    "\n",
    "    def update_params_CNN_layer(self,layer):\n",
    "        layer.filter_weights -= self.learning_rate * layer.filter_weights\n",
    "        layer.filter_biases -= self.learning_rate * layer.filter_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd85ec3b-c24f-4c89-b0d6-41b14565a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:: 2.302567035713741\n",
      "accuracy:: 0.109375\n",
      "loss:: 2.3025618126616614\n",
      "accuracy:: 0.0859375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_range \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_dataset), batch_size):\n\u001b[0;32m     23\u001b[0m     batch_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_dataset[data_range: data_range \u001b[38;5;241m+\u001b[39m batch_size][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     conv_layer1\u001b[38;5;241m.\u001b[39mforward(np\u001b[38;5;241m.\u001b[39marray(train_dataset[data_range: data_range \u001b[38;5;241m+\u001b[39m batch_size][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)) \u001b[38;5;66;03m# Here we enter the input image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     activation_1\u001b[38;5;241m.\u001b[39mfeed_forward(conv_layer1\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     31\u001b[0m     average_pooling_layer_1\u001b[38;5;241m.\u001b[39mpooling(conv_layer1\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_dataset.py:2777\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2776\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2760\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2761\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2762\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2763\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2764\u001b[0m )\n\u001b[0;32m   2765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:653\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    651\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:410\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:467\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    466\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m--> 467\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:229\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdecode_batch(batch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\features.py:2144\u001b[0m, in \u001b[0;36mFeatures.decode_batch\u001b[1;34m(self, batch, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2140\u001b[0m decoded_batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2142\u001b[0m     decoded_batch[column_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2143\u001b[0m         [\n\u001b[1;32m-> 2144\u001b[0m             decode_nested_example(\u001b[38;5;28mself\u001b[39m[column_name], value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[0;32m   2145\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2146\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[0;32m   2148\u001b[0m         ]\n\u001b[0;32m   2149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2150\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[0;32m   2151\u001b[0m     )\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\features.py:1414\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode_example(obj, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id) \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\image.py:187\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 187\u001b[0m image\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Implementation of architecture almost same as LeNet\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "conv_layer1 = Conv_Layer(input_channel=1,input_size=28,stride=1,filter_shape=5,output_chanel_or_filter_num=6,batch_size=batch_size)\n",
    "activation_1 = Activation_Relu()\n",
    "average_pooling_layer_1 = Average_Pooling(2,6,24,batch_size=batch_size)\n",
    "conv_layer2 = Conv_Layer(6,12,1,5,16,batch_size=batch_size)\n",
    "activation_2 = Activation_Relu()\n",
    "average_pooling_layer_2 = Average_Pooling(pooling_frame_size=2,input_channel=16,input_size=8,batch_size=batch_size)\n",
    "conv_layer3 = Conv_Layer(input_channel=16,input_size=4,stride=1,filter_shape=4,output_chanel_or_filter_num=120,batch_size=batch_size)\n",
    "activation_3 = Activation_Relu()\n",
    "fully_conn_layer1 = Layer(n_inputs=120, n_neurons=84)\n",
    "activation_4 = Activation_Relu()\n",
    "fully_conn_layer2 = Layer(n_inputs=84, n_neurons=10)\n",
    "softmax_activation = Softmax()\n",
    "loss_function = Loss_CrossCategorical()\n",
    "accuracy_cls = Accuracy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08333290-bf02-452c-9d70-b3a2e92d7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_range in range(0, len(train_dataset), batch_size):\n",
    "\n",
    "\n",
    "    batch_labels = np.array(train_dataset[data_range: data_range + batch_size]['label'], dtype='int')\n",
    "    \n",
    "    conv_layer1.forward(np.array(train_dataset[data_range: data_range + batch_size]['image'], dtype='float64').reshape(batch_size,1,28,28)) # Here we enter the input image\n",
    "    \n",
    "    \n",
    "    activation_1.feed_forward(conv_layer1.output)\n",
    "    \n",
    "    \n",
    "    average_pooling_layer_1.pooling(conv_layer1.output)\n",
    "    \n",
    "    \n",
    "    conv_layer2.forward(average_pooling_layer_1.output)\n",
    "\n",
    "    # print(f'conv_layer_2_output_shape::{conv_layer3.output.shape}')\n",
    "    \n",
    "    \n",
    "    activation_2.feed_forward(conv_layer2.output)\n",
    "    \n",
    "    \n",
    "    # print(f'conv_layer2_output_shape::{conv_layer2.output.shape}')\n",
    "    average_pooling_layer_2.pooling(activation_2.output)\n",
    "    \n",
    "    \n",
    "    conv_layer3.forward(average_pooling_layer_2.output)\n",
    "    \n",
    "    \n",
    "    activation_3.feed_forward(conv_layer3.output)\n",
    "\n",
    "    # print(f'activation_3 output_shape::{activation_3.output.shape}')\n",
    "    \n",
    "    flatten_output = conv_layer3.output.reshape(batch_size,-1)\n",
    "\n",
    "    # print(f'flatten output_shape::{flatten_output.shape}')\n",
    "    \n",
    "    fully_conn_layer1.feed_forward(flatten_output)\n",
    "    \n",
    "    \n",
    "    activation_4.feed_forward(fully_conn_layer1.output)\n",
    "    \n",
    "    \n",
    "    fully_conn_layer2.feed_forward(activation_4.output)\n",
    "    \n",
    "    \n",
    "    softmax_activation.feed_forward(fully_conn_layer2.output)\n",
    "    \n",
    "    \n",
    "\n",
    "    if(data_range % (batch_size * 11) == 0):\n",
    "        print(f'loss:: {loss_function.calculate(softmax_activation.output,batch_labels)}')\n",
    "        print(f'accuracy:: {accuracy_cls.calculate(softmax_activation.output,batch_labels)}')\n",
    "    \n",
    "    \n",
    "    # Now Do Backprop\n",
    "    loss_function.backward(softmax_activation.output,batch_labels)\n",
    "    softmax_activation.backward(loss_function.dinputs)\n",
    "\n",
    "    fully_conn_layer2.backward(softmax_activation.dinputs)\n",
    "\n",
    "    activation_4.backward(fully_conn_layer2.dinputs)\n",
    "    fully_conn_layer1.backward(activation_4.dinputs)\n",
    "    \n",
    "    activation_3.backward(fully_conn_layer1.dinputs.reshape(activation_3.output.shape))\n",
    "\n",
    "    # print(f'activation_3 output_shape:: {conv_layer3.output.shape}')\n",
    "    \n",
    "    conv_layer3.backward(activation_3.dinputs)\n",
    "    \n",
    "    average_pooling_layer_2.backward(conv_layer3.dinputs)\n",
    "\n",
    "    activation_2.backward(average_pooling_layer_2.dinputs)\n",
    "    conv_layer2.backward(activation_2.dinputs)\n",
    "\n",
    "    average_pooling_layer_1.backward(conv_layer2.dinputs)\n",
    "\n",
    "    activation_1.backward(average_pooling_layer_1.dinputs)\n",
    "    conv_layer1.backward(activation_1.dinputs)\n",
    "\n",
    "    # Now updating the weights and biases\n",
    "    optimizer_general = Optimizer_SGD(lr=0.01)\n",
    "\n",
    "    optimizer_general.update_params(fully_conn_layer1)\n",
    "    optimizer_general.update_params(fully_conn_layer2)\n",
    "\n",
    "    optimizer_general.update_params_CNN_layer(conv_layer1)\n",
    "    optimizer_general.update_params_CNN_layer(conv_layer2)\n",
    "    optimizer_general.update_params_CNN_layer(conv_layer3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
